{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 03 â€“ Modelagem Preditiva com Ajuste para Desbalanceamento\n",
    "\n",
    "Nesta etapa, realizamos a modelagem preditiva para identificar padrÃµes de desligamento. ApÃ³s a anÃ¡lise dos primeiros modelos, percebemos um comportamento tÃ­pico de **desbalanceamento de classes**, onde os modelos previam quase todos os casos como â€œNÃ£o desligamentoâ€, obtendo recall extremamente baixo para a classe 1 (desligamento).\n",
    "\n",
    "## ðŸŽ¯ Problema Identificado\n",
    "- A classe \"Desligamento = Sim\" corresponde a cerca de 20% dos dados.\n",
    "- Modelos como RegressÃ£o LogÃ­stica, Random Forest e LightGBM com parÃ¢metros padrÃ£o apresentaram **acurÃ¡cia ilusÃ³ria** e **recall â‰ˆ 0 para a classe 1**.\n",
    "\n",
    "## âœ… SoluÃ§Ãµes aplicadas\n",
    "1. **Reamostragem com SMOTE**: aumentamos os casos da minoria com tÃ©cnica de oversampling.\n",
    "2. **Ajuste de pesos nos classificadores**:\n",
    "   - `class_weight='balanced'` para LogisticRegression e RandomForest.\n",
    "   - `is_unbalance=True` para LightGBM.\n",
    "3. **AvaliaÃ§Ã£o com mÃ©tricas robustas**:\n",
    "   - Matriz de confusÃ£o\n",
    "   - ROC AUC Score\n",
    "   - F1-score da classe minoritÃ¡ria\n",
    "4. **Ajuste dinÃ¢mico de threshold**:\n",
    "   - AvaliaÃ§Ã£o de thresholds entre 0.1 e 0.9\n",
    "   - VerificaÃ§Ã£o do melhor ponto de equilÃ­brio entre precisÃ£o e recall\n",
    "   - LightGBM com threshold 0.2 apresentou o melhor F1-score (0.39)\n",
    "\n",
    "Essas medidas foram implementadas para melhorar a capacidade preditiva sobre os casos de desligamento real e evitar a ilusÃ£o de desempenho pela acurÃ¡cia geral.\n",
    "\n",
    "## Modelos aplicados:\n",
    "- RegressÃ£o LogÃ­stica\n",
    "- Random Forest\n",
    "- LightGBM\n",
    "\n",
    "Os resultados foram comparados com as abordagens padrÃ£o, com tÃ©cnicas de balanceamento e ajuste de threshold.\n",
    "\n",
    "O script atual aplica todas essas estratÃ©gias de forma integrada, possibilitando testes e comparaÃ§Ãµes para escolha do melhor modelo com base nas mÃ©tricas de negÃ³cio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Œ Modelo: Regressao Logistica\n",
      "Threshold | Precision | Recall | F1-Score | ROC AUC\n",
      "-------------------------------------------------------\n",
      "     0.10 |      0.21 |   1.00 |     0.34 | 0.6137\n",
      "     0.20 |      0.21 |   1.00 |     0.34 | 0.6137\n",
      "     0.30 |      0.21 |   0.99 |     0.35 | 0.6137\n",
      "     0.40 |      0.23 |   0.88 |     0.36 | 0.6137\n",
      "     0.50 |      0.27 |   0.57 |     0.36 | 0.6137\n",
      "     0.60 |      0.32 |   0.22 |     0.26 | 0.6137\n",
      "     0.70 |      0.35 |   0.03 |     0.05 | 0.6137\n",
      "     0.80 |      0.67 |   0.00 |     0.00 | 0.6137\n",
      "     0.90 |      0.00 |   0.00 |     0.00 | 0.6137\n",
      "\n",
      "ðŸ“Œ Modelo: Random Forest\n",
      "Threshold | Precision | Recall | F1-Score | ROC AUC\n",
      "-------------------------------------------------------\n",
      "     0.10 |      0.22 |   0.95 |     0.35 | 0.6075\n",
      "     0.20 |      0.26 |   0.62 |     0.36 | 0.6075\n",
      "     0.30 |      0.31 |   0.20 |     0.24 | 0.6075\n",
      "     0.40 |      0.35 |   0.04 |     0.08 | 0.6075\n",
      "     0.50 |      0.44 |   0.00 |     0.01 | 0.6075\n",
      "     0.60 |      0.50 |   0.00 |     0.00 | 0.6075\n",
      "     0.70 |      1.00 |   0.00 |     0.00 | 0.6075\n",
      "     0.80 |      0.00 |   0.00 |     0.00 | 0.6075\n",
      "     0.90 |      0.00 |   0.00 |     0.00 | 0.6075\n",
      "\n",
      "ðŸ“Œ Modelo: LightGBM\n",
      "[LightGBM] [Info] Number of positive: 14443, number of negative: 55557\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1205\n",
      "[LightGBM] [Info] Number of data points in the train set: 70000, number of used features: 32\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206329 -> initscore=-1.347200\n",
      "[LightGBM] [Info] Start training from score -1.347200\n",
      "Threshold | Precision | Recall | F1-Score | ROC AUC\n",
      "-------------------------------------------------------\n",
      "     0.10 |      0.21 |   1.00 |     0.34 | 0.6395\n",
      "     0.20 |      0.21 |   0.99 |     0.35 | 0.6395\n",
      "     0.30 |      0.22 |   0.95 |     0.36 | 0.6395\n",
      "     0.40 |      0.24 |   0.86 |     0.37 | 0.6395\n",
      "     0.50 |      0.28 |   0.59 |     0.38 | 0.6395\n",
      "     0.60 |      0.34 |   0.26 |     0.30 | 0.6395\n",
      "     0.70 |      0.41 |   0.04 |     0.08 | 0.6395\n",
      "     0.80 |      0.29 |   0.00 |     0.00 | 0.6395\n",
      "     0.90 |      0.00 |   0.00 |     0.00 | 0.6395\n"
     ]
    }
   ],
   "source": [
    "# Modelagem com ajuste para desbalanceamento e thresholds dinÃ¢micos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from scripts.func import preparar_dados_rh\n",
    "\n",
    "# Preparar base com novas features e prÃ©-processamento\n",
    "df_encoded, X_train, X_test, y_train, y_test = preparar_dados_rh(qtd_amostras=100_000)\n",
    "\n",
    "# Modelos com ajustes de balanceamento\n",
    "models = {\n",
    "    'Regressao Logistica': LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced'),\n",
    "    'LightGBM': lgb.LGBMClassifier(random_state=42, is_unbalance=True)\n",
    "}\n",
    "\n",
    "# AvaliaÃ§Ã£o por thresholds\n",
    "thresholds = np.arange(0.1, 0.91, 0.1)\n",
    "\n",
    "# AvaliaÃ§Ã£o com ajuste de threshold\n",
    "for nome, modelo in models.items():\n",
    "    print(f\"\\nðŸ“Œ Modelo: {nome}\")\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"Threshold | Precision | Recall | F1-Score | ROC AUC\")\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    for t in thresholds:\n",
    "        y_pred_thresh = (y_proba >= t).astype(int)\n",
    "        precision = precision_score(y_test, y_pred_thresh, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred_thresh, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred_thresh, zero_division=0)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        print(f\"{t:9.2f} | {precision:9.2f} | {recall:6.2f} | {f1:8.2f} | {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
